{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d4fafc-5a75-4666-9f94-1755aa50343e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"./data/dataset/train.csv\"\n",
    "TEST_DATA_PATH = \"./data/dataset/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20685645-9a84-424a-81ca-aa997f5fd5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(lowercase_text)\n\u001b[1;32m     35\u001b[0m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTITLE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTITLE\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalize_text)\n\u001b[0;32m---> 36\u001b[0m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBULLET_POINTS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBULLET_POINTS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalize_text)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# test data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mnormalize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     20\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m splits \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m splits \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "def fillMissing(df):\n",
    "    df.TITLE.fillna(value=\"missing\", inplace=True)\n",
    "    df.BULLET_POINTS.fillna(value=\"missing\", inplace=True)\n",
    "    df.DESCRIPTION.fillna(value=\"missing\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.replace('\"\"', ' inch')\n",
    "    text = text.replace('\"', '')\n",
    "    text = text.replace('/p', '')\n",
    "    text = text.replace('/b', '')\n",
    "    text = text.replace('-', ' to ')\n",
    "    text = re.sub(r'[^a-zA-Z0-9.:/\\s%_\"]|(?<=\\d)_(?=\\d)', '', text)\n",
    "    text = text.replace('_', ' ')\n",
    "    splits = text.strip().split(' ')\n",
    "    return u\" \".join([x for x in splits if len(x) >= 1])\n",
    "\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "train_data = fillMissing(train_data)\n",
    "test_data = fillMissing(test_data)\n",
    "\n",
    "# train data\n",
    "train_data[\"TITLE\"] = train_data[\"TITLE\"].apply(lowercase_text)\n",
    "train_data[\"BULLET_POINTS\"] = train_data[\"BULLET_POINTS\"].apply(lowercase_text)\n",
    "train_data[\"DESCRIPTION\"] = train_data[\"DESCRIPTION\"].apply(lowercase_text)\n",
    "\n",
    "train_data[\"TITLE\"] = train_data[\"TITLE\"].apply(normalize_text)\n",
    "train_data[\"BULLET_POINTS\"] = train_data[\"BULLET_POINTS\"].apply(normalize_text)\n",
    "train_data[\"DESCRIPTION\"] = train_data[\"DESCRIPTION\"].apply(normalize_text)\n",
    "\n",
    "# test data\n",
    "test_data[\"TITLE\"] = test_data[\"TITLE\"].apply(lowercase_text)\n",
    "test_data[\"BULLET_POINTS\"] = test_data[\"BULLET_POINTS\"].apply(lowercase_text)\n",
    "test_data[\"DESCRIPTION\"] = test_data[\"DESCRIPTION\"].apply(lowercase_text)\n",
    "\n",
    "test_data[\"TITLE\"] = test_data[\"TITLE\"].apply(normalize_text)\n",
    "test_data[\"BULLET_POINTS\"] = test_data[\"BULLET_POINTS\"].apply(normalize_text)\n",
    "test_data[\"DESCRIPTION\"] = test_data[\"DESCRIPTION\"].apply(normalize_text)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31516bd6-02cf-4017-bcce-c6b333bc229f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1c4d4-e9ce-4811-a75c-612896097ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
    "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    ")\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181c35d-fae6-4908-8778-e29187c9fffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, meta_df):\n",
    "        \n",
    "        self.df = meta_df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.df.iloc[index]\n",
    "        title = item[\"TITLE\"]\n",
    "        description = item[\"DESCRIPTION\"]\n",
    "        bullets = item[\"BULLET_POINTS\"]\n",
    "        product_type = item[\"PRODUCT_TYPE_ID\"]\n",
    "        product_length = item[\"PRODUCT_LENGTH\"]\n",
    "        return (title, description, bullets, product_type, product_length)\n",
    "    \n",
    "dev_dataset = AmazonDataset(train_data)\n",
    "test_dataset = AmazonDataset(test_data)\n",
    "\n",
    "train_set_size = int(len(dev_dataset) * 0.8)\n",
    "valid_set_size = len(dev_dataset) - train_set_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dev_dataset, [train_set_size, valid_set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c286f71-0912-4a85-b913-66f4ab95acfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dickies to herren 13 inch multi pocket work short charcoal grey',\n",
       " 'missing',\n",
       " 'sits at waist roomier in seat and thigh skims the kneeflat front with permanent crease 8.5 oz. heavyweight twill 65% polyester/35% cottonsignature long to tunnel belt loops hold heavy tool beltsmulti to use pocket on right legeasy to care stain release wrinkle resistant',\n",
       " 2854,\n",
       " 2350.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13dff0d-520d-4036-83e0-6826cd187c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def data_collate(data, data_transform):\n",
    "    title_feats = []\n",
    "    desc_feats = []\n",
    "    bullet_feats = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sample in data:\n",
    "        title_feats.append(text_transform(sample[0])) #title\n",
    "        desc_feats.append(text_transform(sample[1]))\n",
    "        bullet_feats.append(text_transform(sample[2]))\n",
    "        lengths.append(sample[4])\n",
    "\n",
    "    return title_feats, lengths\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: data_collate(x, text_transform),\n",
    "    num_workers= NUM_WORKERS\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: data_collate(x, text_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c48bbdc-5066-4089-a671-a3e5e4697d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b14794-bec0-434c-a572-4deea22ee07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
